@inproceedings{ociddataset,
  author    = {Markus Suchi and
               Timothy Patten and
               David Fischinger and
               Markus Vincze},
  title     = {EasyLabel: {A} Semi-Automatic Pixel-wise Object Annotation Tool for
               Creating Robotic {RGB-D} Datasets},
  booktitle = {International Conference on Robotics and Automation, {ICRA} 2019,
               Montreal, QC, Canada, May 20-24, 2019},
  pages     = {6678--6684},
  year      = {2019},
  crossref  = {DBLP:conf/icra/2019},
  url       = {https://doi.org/10.1109/ICRA.2019.8793917},
  doi       = {10.1109/ICRA.2019.8793917},
  timestamp = {Tue, 13 Aug 2019 20:25:20 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/icra/SuchiPFV19},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@proceedings{DBLP:conf/icra/2019,
  title     = {International Conference on Robotics and Automation, {ICRA} 2019,
               Montreal, QC, Canada, May 20-24, 2019},
  publisher = {{IEEE}},
  year      = {2019},
  url       = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=8780387},
  isbn      = {978-1-5386-6027-0},
  timestamp = {Tue, 13 Aug 2019 20:23:21 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/icra/2019},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{kmmerer2016deepgaze,
    title={DeepGaze II: Reading fixations from deep features trained on object recognition},
    author={Matthias Kümmerer and Thomas S. A. Wallis and Matthias Bethge},
    year={2016},
    eprint={1610.01563},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{wu2019detectron2,
  author =       {Yuxin Wu and Alexander Kirillov and Francisco Massa and
                  Wan-Yen Lo and Ross Girshick},
  title =        {Detectron2},
  howpublished = {\url{https://github.com/facebookresearch/detectron2}},
  year =         {2019}
}

@misc{gupta2019lvis,
      title={LVIS: A Dataset for Large Vocabulary Instance Segmentation}, 
      author={Agrim Gupta and Piotr Dollár and Ross Girshick},
      year={2019},
      eprint={1908.03195},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@book{kubale2004graph,
  title={Graph Colorings},
  author={Kubale, M. and Optymalizacja Dyskretna English and American Mathematical Society},
  isbn={9780821834589},
  lccn={2004046151},
  series={Contemporary mathematics (American Mathematical Society) v. 352},
  url={https://books.google.ru/books?id=fokbCAAAQBAJ},
  year={2004},
  publisher={American Mathematical Society}
}

@misc{han2021deep,
      title={Deep Learning--Based Scene Simplification for Bionic Vision}, 
      author={Nicole Han and Sudhanshu Srivastava and Aiwen Xu and Devi Klein and Michael Beyeler},
      year={2021},
      eprint={2102.00297},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article {Beyeler148015,
	author = {Beyeler, Michael and Boynton, Geoffrey M. and Fine, Ione and Rokem, Ariel},
	title = {pulse2percept: A Python-based simulation framework for bionic vision},
	elocation-id = {148015},
	year = {2017},
	doi = {10.1101/148015},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {By 2020 roughly 200 million people worldwide will suffer from photoreceptor diseases such as retinitis pigmentosa and age-related macular degeneration, and a variety of retinal sight restoration technologies are being developed to target these diseases. One technology, analogous to cochlear implants, uses a grid of electrodes to stimulate remaining retinal cells. Two brands of retinal prostheses are currently approved for implantation in patients with late stage photoreceptor disease. Clinical experience with these implants has made it apparent that the vision restored by these devices differs substantially from normal sight. To better understand the outcomes of this technology, we developed pulse2percept, an open-source Python implementation of a computational model that predicts the perceptual experience of retinal prosthesis patients across a wide range of implant configurations. A modular and extensible user interface exposes the different building blocks of the software, making it easy for users to simulate novel implants, stimuli, and retinal models. We hope that this library will contribute substantially to the field of medicine by providing a tool to accelerate the development of visual prostheses.},
	URL = {https://www.biorxiv.org/content/early/2017/07/10/148015},
	eprint = {https://www.biorxiv.org/content/early/2017/07/10/148015.full.pdf},
	journal = {bioRxiv}
}
